---
title: "Being a better scientist with open and reproducible research"
tags: ["open science", "open research", "reproducible research", "talks"]
comments: true
---

This blog post summarises the notes for my talk at the [Are you ready
for publishing reproducible
research?](https://www.eventbrite.com/e/are-you-ready-for-publishing-reproducible-research-tickets-55561449792)
meeting at the TU Delft on the 16 May 2019.

{% include toc %}

**Disclaimer**: I do not speak from authority[^auth]. I speak of personal
experience. My experience is in computational biology, bioinformatics
and high throughput biolofy data. My experience doesn't directly
translate to other fields or domains (for example when it comes to
data privacy) or even to other personalities in the same field.

[^auth]: I actually think that authority (or seniority) isn't doing
    any favours when it comes to open research and
    reproducibility. The more senior stakeholder all too often aren't
    those that drive research toward more openness and
    reproducibility. There are, fortunately, notable exceptions.

**Note 1:** A priece of open research doesn't automatically make it good,
where good is defined as of high academic quality. A piece of closed
research doesn't make it bad, where bad here is defined of low
academic quality. So openness doens't equate to academic quality. But
openness provides some desired quality (i.e. desirable property)
independent from academic excellent. Openness leads to trust.

**Note 2:** A priece of reproducible research doesn't automatically make
it good, where good is defined as of high academic quality. A piece of
non reproducible research doesn't make it bad, where bad here is
defined of low academic quality. So reproducible doesn't equate to
academic quality. But reproducibility provides some desired quality
(i.e. desirable property) independent from academic
excellent. Reproducibility leads (among other things) to trust.

**Note 3:** Open research and reproducible research aren't the same
thing, and one doesn't imply the other. They are historically also
very different (see the links in this
[tweet](https://twitter.com/o_guest/status/1068791012481470464) by
Oliva Guest).

From a technical point of view:

- When individual patronage funded scientists, discoveries were kept
  private or publicised as codes in anagrams or cyphers (Source
  [Wikipedia:Open
  Science](https://en.wikipedia.org/wiki/Open_science#History)).
- The concept of open access to scientific data was institutionally
  established with the formation of the World Data Center system (now
  the World Data System). MEDLINE, later renamed PubMed, was created
  in 1966. (Source [Wikipedia:Open Science
  Data](https://en.wikipedia.org/wiki/Open_science_data#History)).


From a philosophical point of view:

**[The Mertonian norms](https://en.wikipedia.org/wiki/Mertonian_norms) (1942)**

- *communism*: all scientists should have common ownership of scientific
  goods (intellectual property), to promote collective collaboration;
  secrecy is the opposite of this norm.

- *universalism*: scientific validity is independent of the
  sociopolitical status/personal attributes of its participants.

- *disinterestedness*: scientific institutions act for the benefit of a
  common scientific enterprise, rather than for the personal gain of
  individuals within them
  
- *organized scepticism*: scientific claims should be exposed to
  critical scrutiny before being accepted: both in methodology and
  institutional codes of conduct.

## There isn't only one type of open science

Open science has seen a continous evolution since the 17th centure,
with the advent of dissemination of reserach in scientific journals
and the societal demand to access scientific knowledge at
large. Technology and communication has further accelerated this
evolution, and put it in the spot light among researchers and
academics (for for examples funder mandates) and more widely in the
press with the cost of publications (see for example this Guardian
*long read* article [Is the staggeringly profitable business of
scientific publishing bad for
science?](https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science)
or the [Paywall](https://paywallthemovie.com/) movie).

Open science/research is the process of transparent dissemination and
access to knowledge, that can be applied to various scientific
practices:

![The six principles of open science](https://en.wikipedia.org/wiki/Open_science#/media/File:Open_Science_-_Prinzipien.png)

As a result

> Open science/research can mean different things to different people,
> in particular when declined along its many technical and
> philosophical attributes.

and

> Open isn't binary, it's a gradient.

How to be an open scientist: 

> Let's be open and understanding of different situations and
> constraints.

## Why open and reproducible research?

### Why becoming an open research practitioners

It's th right thing to do. See the **The Mertonian norms**... Or is it?

**Benefits for your academic career**: some examples from the [**Open
as a career boost**](https://lgatto.github.io/EPFL-open-science/)
paragraph:

- Open access articles get more citations.
- Data availability is associated with citation benefit.

**Networking opportunities** (I'm here thanks to my open research
activities with my former colleage Marta Teperek at the University of
Cambridge, UK).

See also [**Why Open Research**](http://whyopenresearch.org/index)

- **Increase your visibility**: Build a name for yourself. Share your
  work and make it more visibile.

- **Reduce publishing costs**: Open publishing can cost the same or
  less than traditional publishing.

- **Take back control**: Know your rights. Keep your rights. Decide
  how your work is used

- **Get more funding**: Meet funder requirements, and qualify for
  special funds such as the Wellcome Trust [Open Research
  Fund](https://wellcome.ac.uk/funding/schemes/open-research-fund).

- **Publish where you want**: Publish in the journal of your choice
  and archive an open copy. (See [The cost of
  knowledge](http://thecostofknowledge.com/) boycott of Elsevier).
  
- **Get that promotion**: Open research is increasingly recognized in
  promotion and tenure. See also [Reproducibility and open science are
  starting to matter in tenure and
  promotion](https://cos.io/blog/are-reproducibility-and-open-science-starting-matter-tenure-and-promotion-review/)
  July 14th, 2017, Brian Nosek) and the EU's [Evaluation of Research
  Careers fully acknowledging Open Science
  Practice](https://cdn1.euraxess.org/sites/default/files/policy_library/os-rewards-wgreport-final_integrated_0.pdf)
  defines an Open Science Career Assessment Matrix (OS-CAM):

But are there **any risks**?

> Does it take more time to work openly? 

Isn't it worth investing time is managing data in a way that others
(including future self) can find and understand it? That's, IMHO,
particularly important from a group leader's perspective, where I want
to build a corpus of data/software/research that other lab members can
find, mine and re-use.

> Are senior academics always supportive?

No.

> Is there a risk of being scooped?

There certainly is a benefit if releasing one's research early!

But, importantly, working with open and reproducible research in mind
doesn't mean releasing everything prematurely, it means

- managing research in a way one can find data and results at every
  stage

- one can reproduce results, re-run/compare them with new data or
  different methods/parameters, and

- one can release data (or parts thereof) when/if appropriate.

## Why reproducibility is important

- For **scientific reasons**: think reproducibility crisis.

- For **political reasons**: public trust in science, in data, in
  experts; without (public) trust in science and research, there won't
  be any funding anymore.

[But what to we mean by reproducibility?](https://lgatto.github.io/rr-what-should-be-our-goals/)

- **Repeat** my experiment, i.e. obtain the same tables/graphs/results
  using the same setup (data, software, ...) in the same lab or on the
  same computer. That's basically re-running one of my analysis some
  time after I original ndeveloped it.

- **Reproduce** an experiment (not mine), i.e. obtain the same
  tables/graphs/results in a different lab or on a different computer,
  using the same setup (the data would be downloaded from a public
  repository and the same software, but possibly different version,
  different OS, is used). I suppose, we should differentiate
  replication using a fresh install and a virtual machine or docker
  image that replicates the original setup.

- **Replicate** an experiment, i.e. obtain the same (similar enough)
  tables/graphs/results in a different set up. The data could still be
  downloaded from the public repository, or possibly
  re-generate/re-simulate it, and the analysis would be re-implemented
  based on the original description. This requires openness, and one
  would clearly not be allowed the use a black box approach (VM,
  docker image) or just re-running a script.

- Finally, **re-use** the information/knowledge from one experiment to
  run a different experiment with the aim to confirm results from
  scratch.

Another view (from a talk by [Kirstie
Whitaker](https://figshare.com/articles/Publishing_a_reproducible_paper/4720996/1)):

|                | Same Data | Different Data |
|----------------|-----------|----------------|
| Same Code      | reproduce | replicate      |
| Different Code | robust    | generalisable  |


See also this opinion pieve by Jeffrey T. Leek and Roger D. Peng,
[*Reproducible research can still be wrong: Adopting a prevention
approach*](https://www.pnas.org/content/112/6/1645).


<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">It’s better not to use reproducibility and replicability interchangeably:<br><br>reproducibility = get same results from data and code<br>replicability = get similar results from new experiment<br><br>So most research is not reproducible, let alone replicable. <a href="https://t.co/K7XL2vcoWi">pic.twitter.com/K7XL2vcoWi</a></p>&mdash; Guillaume Rousselet (@robustgar) <a href="https://twitter.com/robustgar/status/1127890626345938947?ref_src=twsrc%5Etfw">May 13, 2019</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


## Types of reproducibiliy

See also 

> An Imperfect Guide to Imperfect Reproducibility (2019) May Institute
> for Computational Proteomics
> (https://gmbecker.github.io/MayInstituteKeynote2019/outline.html)


- (Computational) Reproducibility Is Not The Point

Trust, Verification and Guarantees

- **Trust in Reporting** - result is accurately reported
- **Trust in Implementation** - analysis code successfully implements
  chosen methods
- **Statistical Trust** - data and methods are (still) appropriate
- **Scientific Trust** - result convincingly supports claim(s) about
  underlying systems or truths

Reproducibility As A Trust Scale

![Reproducibility As A Trust Scale](https://gmbecker.github.io/MayInstituteKeynote2019/trustscale3.png)

Take home message:

> Reproducibility isn't binary, it's a gradient.


## Why becoming a reproducible research practitioners

> And so, my fellow scientists: ask not what you can do for
> reproducibility; ask what reproducibility can do for you! Here, I
> present five reasons why working reproducibly pays off in the long
> run and is in the self-interest of every ambitious, career-oriented
> scientist.

Florian Markowetz, **Five selfish reasons to work reproducibly**,
Genome Biology 2015, 16:274. https://doi.org/10.1186/s13059-015-0850-7

1. Reason number 1: reproducibility helps to avoid disaster
2. Reason number 1: reproducibility helps to avoid disaster
3. Reason number 3: reproducibility helps reviewers see it your way
4. Reason number 3: reproducibility helps reviewers see it your way
5. Reason number 5: reproducibility helps to build your reputation


And career perspectives: [Faculty promotion must assess
reproducibility](https://www.nature.com/news/faculty-promotion-must-assess-reproducibility-1.22596).

## What can you do to improve trust in research?

1. **Be an open research practitioners**
2. **Be an reproducible research practitioners**

Includes (but not limited to)

### Preprints are the best!

- Read, post, review **preprints** (see
  [ASAPbio](https://asapbio.org/) for lots of resources about
  preprints).

### Promoting open research through peer review

This section is based on my [The role of peer-reviewers in ~~checking
supporting information~~ promoting open
science](https://rawgit.com/lgatto/2017-03-30-OSC-peerreview/master/slides.html)
talk.

As an open researcher, I think it is important to apply and promote
the importance of data and good data management on a day-to-day basis
(see for example Marta Teperek's 2017 [Data Management: Why would I
bother?](http://doi.org/10.5281/zenodo.897785) slides), but also to
express this ethic in our academic capacity, such as peer review. My
responsibility as a reviewer is to

* Accept sound/valid research and provide constructive comments

and hence

* Focus firstly on the validity of the research by inspecting the
  data, software and method. If the methods and/or data fail, the rest
  is meaningless.

I don't see novelty, relevance, news-worthiness as my business as a
reviewer. These factors are not the prime qualities of thorough
research, but rather characteristics of flashy news.

Here are some aspects that are easy enough to check, and go a long way
to verify the availability and validity and of the data

1. **Availability**: Are the data/software/methods accessible and
   understandable in a way that would allow an informed researcher in
   the same or close field to reproduce and/or verify the results
   underlying the claims? Note that this doesn't mean that as a
   reviewer, I will necessarily try to repeat the whole analysis (that
   would be too time consuming indeed). But, conversely, a submission
   without data/software will be reviewed (and rejected, or more
   appropriately send back for completion) in matters of minutes. Are
   the data available in a public repository that guarantees that it
   will remain accessible, such as a subject-specific or, if none is
   available, a generic repository (such
   as [zenodo](https://zenodo.org/)
   or [figshare](https://figshare.com/), ...), an institutional
   repository (we have [Apollo](https://www.repository.cam.ac.uk/) at
   the University of Cambridge), or, but less desirable, supplementary
   information or a personal webpage[^4].

2. **Meta-data**: It's of course not enough to provide a wild dump of
   the data/software/..., but these need to be appropriately
   documented. Personally, I recommend an `README` file in every top
   project directory to summarise the project, the data, ...

3. **Do numbers match?**: The first thing when reproducing someone's
   analysis is to match the data files to the experimental
   design. That is one of the first things I check when reviewing a
   paper. For example if the experimental design says there are 2
   groups, each with 3 replicates, I expect to find 6 (or a multiple
   thereof) data files or data columns in the data matrix. Along these
   lines, I also look at the file names (of column names in the data
   matrix) for a consistent naming convention, that allows to match
   the files (columns) to the experimental groups and replicates.
  
4. **What data, what format**: Is the data readable with standard and
   open/free software? Are the raw and processed available, and have
   the authors described how to get from one to the other? 

5. **License**: Is the data shared in a way that allows users to
   re-use it. Under what conditions? Is the research output shared
   under a valid license?

[^4]: There is often no perfect solution, and a combination of the above might be desirable.

Make sure that the data adhere to the
**[FAIR](http://www.nature.com/articles/sdata201618) principles**:

>  Findable and Accessible and Interoperable and Reusable

Note that SI are not FAIR, not discoverable, not structured,
voluntary, used to bury stuff. A personal web page is likely to
disappear in the near future.

As a quick note, my *ideal* review system would be one where

1. Submit your data to a repository, where it get’s checked (by
   specialists, data scientists, data curators) for quality,
   annotation, meta-data.

2. Submit your research with a link to the peer reviewed data. First
   review the intro and methods, then only the results (to avoid
   positive results bias).

When talking about open research and peer review, one logical
extension is **open peer review**. While I personally value open peer
review and practice it when possible, it can be a difficult issue for
ECRs, exposing them unnecessarily when reviewing work from prominent
peers. It also can reinforce an already unwelcoming environment for
underrepresented minorities. See more about this in the *Inclusivity:
open science and open science* section below.

### Make alies 

- other ECR
- librarians
- data stewards/champions
- Research Software engineers
- on-line networking

### Just do it!


> Build openness at the core your research


### Technical solutions

- Scripting, scripting, scripting.

- Avoid manual steps.

- Document everything, especially manual steps (which you should avoid anyway).

- Version control, such as git/github, bitbucket, ...

- Literate analyses: reproducible documents with Rmarkdown, Sweave (R
  with LaTeX), Juyter notebooks, ...

- Shareable compute environments (docker containers).


See See also *An Imperfect Guide to Imperfect Reproducibility*
(https://gmbecker.github.io/MayInstituteKeynote2019/outline.html) for
further details.


## Inclusivity: [open research and open research](https://lgatto.github.io/open-and-open/)

There is 

> Open Science as in widely disseminated and openly accessible

and

> Open Science as in inclusive and welcoming

On being inclusive -
[Twitter thread](https://twitter.com/CameronNeylon/status/895546085468495873) by
[Cameron Neylon](https://twitter.com/CameronNeylon):

<blockquote class="twitter-tweet" data-lang="en"><p lang="en"
dir="ltr">The primary value proposition of <a
href="https://twitter.com/hashtag/openscience?src=hash">#openscience</a>
is that diverse contributions allow better critique, refinement, and
application 3/n</p>&mdash; CⓐmeronNeylon (@CameronNeylon) <a
href="https://twitter.com/CameronNeylon/status/895546764861853696">August
10, 2017</a></blockquote> <script async
src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<blockquote class="twitter-tweet" data-conversation="none"
data-lang="en"><p lang="en" dir="ltr">It was a damned hard community
to break into. Any step I took to be more open, I felt attacked for
not doing enough/doing it right.</p>&mdash; Christie Bahlai (@cbahlai)
<a href="https://twitter.com/cbahlai/status/871413258107981824">June
4, 2017</a></blockquote> <script async
src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

As far as I was concerned for a long time (until June 2017 to be
accurate - this section is based this [Open science and open
science](https://lgatto.github.io/open-and-open/) post), the former
more technical definition was always what I was focusing on, and the
second community-level aspect of openness was, somehow, implicit from
the former, but that's not the case.

Even if there are efforts to promote diversity, under-represented
minorities (URM) don't necessarily feel
[included](http://science.sciencemag.org/content/357/6356/1101.full).
When it comes to open science/research URMs can be further
discriminated against by greater exposure or, can't always afford to
be vocal.

- Not everybody has the privilege to be open.
- There are different levels in how open one wants, or how open one
  could afford to be.
- Every voice and support is welcome.


## Conclusions

> **Standing on the shoulders of giants** only really makes sense in
> the context of open and reproducible research.

- If you are here, chances are you are on the path towards open and
  reproducible research.

- You are the architect of the kind of research and researcher you
  want to become. I hope these include openness and reproducibility.

- It's a long path, that constantly evolves, depending on constraints,
  aspirations, environment, ...
  
- The sky is the limit, be creative: work out the (open and
  reproducible) research that works for you now ...
  
- ... and that you want to work (for you and others) in the future. 
  
